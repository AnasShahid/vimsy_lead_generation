---
phase: 1
plan: 3
name: AI Analysis Service & Geographic Filtering
wave: 2
depends_on: [01-02]
autonomous: true
---

# Phase 1 Plan 3: AI Analysis Service & Geographic Filtering

## Objective

Build an AI analysis service that enriches discovered sites with industry/segment classification, "why they're a good fit" reasoning, and Hot/Warm/Cold priority scoring — trained on Vimsy's business context. Also add geographic filtering to limit discovery results to English-speaking markets (AU, US, UK, NZ, CA). Finally, update the results table to display the new enrichment columns.

## Context

**Requirements addressed:** REQ-013 (AI analysis portion), REQ-015
**Phase goal contribution:** Completes the enriched discovery output — sites discovered through any provider can be AI-analyzed to match the vimsy_cold_outreach_leads format. Geographic filtering ensures only target markets are processed.

## Tasks

### Task 1: Create AI analysis service

**Files:** `server/src/services/ai-analyzer.ts`, `server/package.json`

**Action:**
1. Install OpenAI SDK: add `openai` to `server/package.json` dependencies
2. Add `OPENAI_API_KEY` to `.env.example`

3. Create `server/src/services/ai-analyzer.ts`:
   - Export `analyzeSites(siteIds: number[]): Promise<void>`
   - For each site (or in batches of 5-10 for efficiency):
     - Fetch site data from database
     - Build prompt with Vimsy business context:
       ```
       You are analyzing websites for Vimsy, a WordPress maintenance service.
       Vimsy targets businesses that:
       - Run WordPress sites but lack dedicated dev teams
       - Depend on their website for revenue (e-commerce, lead gen, bookings)
       - Are small-to-medium businesses in AU, US, UK, NZ, CA
       
       For each site, provide:
       1. Company Name (infer from domain/page title)
       2. Industry / Segment (e.g., "E-commerce (Food)", "Professional Services")
       3. Why They're a Good Fit (2-3 sentences explaining fit for Vimsy's services)
       4. Priority: Hot (strong fit, likely needs help), Warm (moderate fit), Cold (weak fit)
       ```
     - Send site data (domain, page_title, meta_description, wp_version, detected_plugins, detected_theme, has_contact_page) as context
     - Parse structured JSON response
     - Update site record via `upsertSite()` with: `company_name`, `industry_segment`, `ai_fit_reasoning`, `priority`
   - Use `gpt-4o-mini` model for cost efficiency (configurable via env var `AI_MODEL`)
   - Handle rate limits with exponential backoff
   - Handle API errors gracefully — log and skip failed sites, don't crash batch

4. Export `analyzesSingleSite(siteId: number): Promise<void>` for one-off analysis

**Verify:**
```bash
grep "analyzeSites" server/src/services/ai-analyzer.ts
grep "openai" server/package.json
grep "OPENAI_API_KEY" .env.example
```

**Done when:**
- AI analyzer service exists with batch and single-site analysis
- Uses OpenAI API with Vimsy-specific prompt
- Updates site records with AI-generated enrichment fields
- Handles errors without crashing

---

### Task 2: Create AI analysis API endpoint and background job

**Files:** `server/src/routes/sites.ts`, `server/src/workers/discovery-worker.ts`

**Action:**
1. In `server/src/routes/sites.ts`, add new endpoint:
   - `POST /api/sites/analyze` — accepts `{ siteIds: number[] }` or `{ all: true, filters?: { is_wordpress?: boolean, priority?: string } }`
   - Creates a job of type `'analysis'` (reuse existing job infrastructure) or runs inline for small batches (<10 sites)
   - For large batches: create a job and let the worker pick it up
   - For small batches: run `analyzeSites()` directly and return results

2. In `server/src/workers/discovery-worker.ts` (or create a new `analysis-worker.ts`):
   - Handle jobs of type `'enrichment-ai'` (to distinguish from Step 3 technical analysis)
   - Job config contains `{ siteIds: number[] }`
   - Calls `analyzeSites()` with progress tracking
   - Updates job progress as sites are processed

3. Add a simple `POST /api/sites/:id/analyze` endpoint for single-site analysis

**Verify:**
```bash
grep "analyze" server/src/routes/sites.ts
grep "enrichment-ai" server/src/workers/discovery-worker.ts
```

**Done when:**
- `POST /api/sites/analyze` endpoint accepts batch or filtered analysis requests
- `POST /api/sites/:id/analyze` works for single sites
- Large batches run as background jobs with progress tracking
- Small batches return results inline

---

### Task 3: Add geographic filtering

**Files:** `server/src/db/queries/sites.ts`, `shared/types.ts`, `client/src/pages/DiscoveryPage.tsx`

**Action:**
1. The `country` field already exists on the `sites` table. Ensure it's populated:
   - In the AI analyzer (Task 1), add country detection to the prompt: "Infer the likely country from the domain TLD (.com.au → AU, .co.uk → UK, .co.nz → NZ, .ca → CA) and site content language"
   - In discovery providers, extract country from TLD where possible (e.g., `.com.au` → `AU`)

2. In `server/src/db/queries/sites.ts`:
   - The `listSites` function already supports `country` filter from Plan 2
   - Add a constant for target markets: `const TARGET_MARKETS = ['AU', 'US', 'UK', 'NZ', 'CA']`
   - Add filter option `english_markets_only?: boolean` to `SiteFilterParams` in `shared/types.ts`
   - When `english_markets_only` is true, add `WHERE country IN ('AU', 'US', 'UK', 'NZ', 'CA')` clause

3. In `client/src/pages/DiscoveryPage.tsx`:
   - Add a "Market" filter dropdown to the filters section:
     - Options: All, AU, US, UK, NZ, CA, English Markets Only
     - "English Markets Only" sends `english_markets_only: true`
     - Individual country sends `country: 'AU'` etc.

**Verify:**
```bash
grep "TARGET_MARKETS\|english_markets_only" server/src/db/queries/sites.ts
grep "english_markets_only" shared/types.ts
grep "Market" client/src/pages/DiscoveryPage.tsx
```

**Done when:**
- Country is inferred from TLD during discovery and from AI analysis
- Sites can be filtered by individual country or "English Markets Only"
- Filter dropdown appears in DiscoveryPage UI

---

### Task 4: Update results table to display enrichment columns

**Files:** `client/src/components/discovery/SiteResultsTable.tsx`

**Action:**
1. Add new columns to the results table:
   - **Company** — `company_name` (with domain as fallback)
   - **Industry** — `industry_segment`
   - **Priority** — `priority` with color-coded badge (Hot=red, Warm=orange, Cold=blue)
   - **Fit** — `ai_fit_reasoning` (truncated to ~80 chars with tooltip for full text)
   - **Emails** — `emails_available_count`
   - **Status** — `outreach_status` with badge

2. Reorder columns for the enriched view:
   - Company | Domain | Industry | Priority | Fit Reasoning | Emails | WP Version | Outreach Status
   - Keep existing columns (url, is_wordpress, etc.) but deprioritize them visually

3. Add a "Run AI Analysis" button:
   - Appears in the table header or as a bulk action
   - When clicked with selected sites (or all filtered sites), calls `POST /api/sites/analyze`
   - Shows loading state while analysis runs
   - Refreshes table when complete

4. Make Priority column sortable (add to sort options)

**Verify:**
```bash
grep "company_name\|industry_segment\|priority\|ai_fit_reasoning" client/src/components/discovery/SiteResultsTable.tsx
grep "Run AI Analysis\|analyze" client/src/components/discovery/SiteResultsTable.tsx
```

**Done when:**
- Results table shows enrichment columns (company, industry, priority, fit, emails, outreach status)
- Priority badges are color-coded
- "Run AI Analysis" button triggers batch analysis
- Table refreshes after analysis completes
- Priority column is sortable

---

## Verification

After all tasks complete:

```bash
# Server compiles
cd server && npx tsc --noEmit

# Client compiles
cd client && npx tsc --noEmit

# AI service exists
ls server/src/services/ai-analyzer.ts

# Endpoints exist
grep -c "analyze" server/src/routes/sites.ts

# Geographic filtering
grep "english_markets_only" server/src/db/queries/sites.ts

# Table columns
grep "company_name" client/src/components/discovery/SiteResultsTable.tsx
```

## Success Criteria

- [ ] AI analysis service enriches sites with company name, industry, fit reasoning, and priority
- [ ] Batch and single-site analysis endpoints work
- [ ] Large batches run as background jobs with progress tracking
- [ ] Geographic filtering by country and "English Markets Only" works in API and UI
- [ ] Country inferred from TLD during discovery and from AI analysis
- [ ] Results table displays all enrichment columns with proper formatting
- [ ] Priority badges are color-coded (Hot/Warm/Cold)
- [ ] "Run AI Analysis" button triggers batch analysis from UI
- [ ] TypeScript compiles on both server and client

## Output

**Files created:**
- `server/src/services/ai-analyzer.ts` — AI analysis service with OpenAI integration

**Files modified:**
- `server/package.json` — Add openai dependency
- `.env.example` — Add OPENAI_API_KEY, AI_MODEL
- `server/src/routes/sites.ts` — Add analyze endpoints
- `server/src/workers/discovery-worker.ts` — Handle enrichment-ai job type
- `server/src/db/queries/sites.ts` — Geographic filtering (english_markets_only)
- `shared/types.ts` — Add english_markets_only to SiteFilterParams
- `client/src/pages/DiscoveryPage.tsx` — Add Market filter dropdown
- `client/src/components/discovery/SiteResultsTable.tsx` — Display enrichment columns, add AI analysis button
