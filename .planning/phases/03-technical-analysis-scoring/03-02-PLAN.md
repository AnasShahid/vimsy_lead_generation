---
phase: 3
plan: 2
name: Analysis Services — PSI, SSL, WPScan & Scoring
wave: 2
depends_on: ["03-01"]
autonomous: true
---

# Phase 3 Plan 2: Analysis Services — PSI, SSL, WPScan & Scoring

## Objective

Implement the three core analysis services (PageSpeed Insights, SSL/TLS, WPScan), the local vulnerability database matching system, and the composite scoring engine. Wire them into the analysis worker so that when a job runs, each site gets a full technical analysis with a 0-100 health score.

## Context

**Requirements addressed:** REQ-018, REQ-019, REQ-020, REQ-021
**Phase goal contribution:** This is the analytical core — without these services, there's no data to score or display. After this plan, running an analysis job produces real results stored in `site_analyses`.

## Tasks

### Task 1: PageSpeed Insights Service

**Files:** `server/src/services/analysis/pagespeed.ts`

**Action:**

Create PageSpeed Insights service that calls Google's PSI API:

```typescript
interface PageSpeedResult {
  performance: number;      // 0-100
  accessibility: number;    // 0-100
  seo: number;              // 0-100
  bestPractices: number;    // 0-100
  rawData: Record<string, unknown>;  // Full Lighthouse JSON for storage
  error?: string;
}
```

Implementation:
- Call `https://www.googleapis.com/pagespeedonline/v5/runPagespeed`
- Parameters: `url`, `key` (GOOGLE_API_KEY from env), `strategy=mobile`, `category=performance,accessibility,best-practices,seo`
- Parse response: extract `lighthouseResult.categories.*.score` (multiply by 100)
- Use existing `fetchUrl` from `utils/http.ts`
- Rate limiting: simple delay (250ms between requests = ~4/sec, well under 240/min limit)
- Timeout: 60 seconds per request (Lighthouse can be slow)
- Handle errors gracefully: return partial results if some categories fail, return error string if complete failure
- Handle non-200 responses: 429 (rate limit), 400 (invalid URL), 500 (API error)

**Verify:**
```bash
cd server && npx tsc --noEmit
```

**Done when:**
- `analyzePageSpeed(url: string)` function exported
- Returns all four Lighthouse scores + raw data
- Rate limiting prevents hitting API limits
- Errors don't crash — return error string in result

---

### Task 2: SSL/TLS Analysis Service

**Files:** `server/src/services/analysis/ssl-analyzer.ts`

**Action:**

Create SSL/TLS analysis service using Node.js `tls` and `https` modules:

```typescript
interface SSLAnalysisResult {
  valid: boolean;
  issuer: string | null;
  subject: string | null;
  expiryDate: string | null;
  daysUntilExpiry: number | null;
  protocolVersion: string | null;
  cipher: string | null;
  cipherStrength: number | null;  // bits
  chainValid: boolean;
  selfSigned: boolean;
  errors: string[];
  rawData: Record<string, unknown>;
}
```

Implementation:
- Use `tls.connect()` to establish TLS connection to the domain on port 443
- Extract certificate info: `socket.getPeerCertificate(true)` for full chain
- Parse certificate fields:
  - `valid_from`, `valid_to` → calculate days until expiry
  - `issuer.O` → issuer organization
  - `subject.CN` → subject common name
  - Check if self-signed: issuer === subject
- Get protocol: `socket.getProtocol()` (TLSv1.2, TLSv1.3, etc.)
- Get cipher: `socket.getCipher()` → name and bits
- Validate chain: check `socket.authorized` and `socket.authorizationError`
- Timeout: 10 seconds for connection
- Handle errors: connection refused, timeout, certificate errors → return with `valid: false` and error details
- Handle non-HTTPS sites: return `valid: false` with appropriate message

**Verify:**
```bash
cd server && npx tsc --noEmit
```

**Done when:**
- `analyzeSSL(domain: string)` function exported
- Detects expired certs, weak protocols, self-signed, chain issues
- Returns structured data for scoring and storage
- Works on both valid and invalid SSL sites without crashing

---

### Task 3: WPScan Integration Service

**Files:** `server/src/services/analysis/wpscan.ts`

**Action:**

Create WPScan service that executes scans via Docker:

```typescript
interface WPScanResult {
  wpVersion: string | null;
  wpVersionStatus: string | null;  // 'latest', 'outdated', 'insecure'
  mainTheme: { name: string; version: string | null } | null;
  plugins: Array<{ slug: string; name: string; version: string | null; outdated: boolean }>;
  users: string[];
  configBackups: string[];
  dbExports: string[];
  interestingFindings: string[];
  rawData: Record<string, unknown>;
  error?: string;
}
```

Implementation:
- Execute WPScan via Docker exec: `docker exec wpscan wpscan --url <url> --format json --enumerate vp,vt,cb,dbe --no-banner --random-user-agent`
- Use Node.js `child_process.execFile` or `exec` to run the docker command
- Parse JSON output from WPScan
- Extract:
  - `version.number` and `version.status` (latest/outdated/insecure)
  - `main_theme` with name and version
  - `plugins` array with slug, version, outdated status
  - `users` array
  - `config_backups` and `db_exports`
  - `interesting_findings` array
- Timeout: 120 seconds per scan (WPScan can be slow on large sites)
- Handle non-WordPress sites: WPScan returns error → catch and return `error: 'Not a WordPress site'`
- Handle Docker not running: catch exec error → return meaningful error
- Use `--force` flag to scan even if WPScan isn't sure it's WordPress (we already know from discovery)

For development without Docker, provide a fallback that returns a mock/empty result with an error message indicating Docker is required.

**Verify:**
```bash
cd server && npx tsc --noEmit
```

**Done when:**
- `runWPScan(url: string)` function exported
- Executes WPScan via Docker and parses JSON output
- Extracts all relevant fields (version, plugins, themes, users, backups)
- Handles Docker-not-available gracefully
- Timeout prevents hanging on unresponsive sites

---

### Task 4: Vulnerability Matching Service

**Files:** `server/src/services/analysis/vulnerability-matcher.ts`

**Action:**

Create vulnerability matching service that cross-references WPScan findings with the local vulnerability database:

```typescript
interface VulnerabilityMatch {
  software_slug: string;
  software_type: 'plugin' | 'theme' | 'core';
  detected_version: string | null;
  vulnerabilities: Array<{
    title: string;
    cve_id: string | null;
    cvss_score: number | null;
    cvss_rating: string | null;
    patched_status: string | null;
    remediation: string | null;
  }>;
}

interface VulnerabilityMatchResult {
  matches: VulnerabilityMatch[];
  totalVulnerabilities: number;
  criticalCount: number;
  highCount: number;
  mediumCount: number;
  lowCount: number;
}
```

Implementation:
1. **Local DB lookup (primary):** Query `wp_vulnerabilities` table by `software_slug` for each detected plugin/theme/core version
2. **Version matching:** Compare detected version against `affected_versions` field to determine if the installed version is vulnerable
3. **Fallback API lookup:** If slug not found locally, try:
   - Wordfence: `GET https://www.wordfence.com/api/intelligence/v2/vulnerabilities/software/{slug}`
   - WPVulnerability: `GET https://www.wpvulnerability.net/plugin/{slug}/`
4. **Aggregate results:** Count by severity (critical/high/medium/low based on CVSS score ranges)

Version comparison logic:
- Parse `affected_versions` string (e.g., `"<= 5.2.1"`, `"< 3.0"`)
- Use semver-style comparison to check if detected version falls in affected range
- If version unknown, flag as potentially vulnerable

**Verify:**
```bash
cd server && npx tsc --noEmit
```

**Done when:**
- `matchVulnerabilities(wpscanResult)` function exported
- Queries local DB first, falls back to APIs
- Returns structured vulnerability data with severity counts
- Handles missing versions gracefully

---

### Task 5: Vulnerability Database Import & Settings Integration

**Files:** `server/src/services/analysis/vuln-db-updater.ts`, `server/src/routes/settings.ts`

**Action:**

Create vulnerability database updater:
- Download OWVD SQLite from GitHub: `https://github.com/ihuzaifashoukat/wordpress-vulnerability-database/raw/main/vulnerabilities.db`
- Or download CSV: `https://github.com/ihuzaifashoukat/wordpress-vulnerability-database/raw/main/vulnerabilities.csv`
- Parse and bulk-insert into local `wp_vulnerabilities` table
- Clear existing data before import (full refresh)
- Track import date in `settings` table (`vuln_db_last_updated`)
- Return stats: total imported, by type, by severity

Add to settings routes:
- `POST /api/settings/vuln-db/update` — Trigger vulnerability DB update (downloads and imports)
- `GET /api/settings/vuln-db/status` — Get last update date and stats

Use CSV approach (simpler to parse in Node.js than reading a SQLite file):
- Download CSV with `fetchUrl`
- Parse with existing `csv-parse` dependency
- Bulk insert with prepared statement in a transaction

**Verify:**
```bash
cd server && npx tsc --noEmit
```

**Done when:**
- `updateVulnerabilityDatabase()` downloads and imports OWVD data
- Settings routes expose update trigger and status
- Import runs in a transaction for atomicity
- Stats tracked in settings table

---

### Task 6: Composite Scoring Engine

**Files:** `server/src/services/analysis/scoring.ts`

**Action:**

Create the scoring engine that combines all analysis dimensions into a 0-100 health score:

```typescript
interface ScoringInput {
  pagespeed: PageSpeedResult | null;
  ssl: SSLAnalysisResult | null;
  wpscan: WPScanResult | null;
  vulnerabilities: VulnerabilityMatchResult | null;
}

interface ScoringOutput {
  healthScore: number;           // 0-100 composite
  securityScore: number;         // 0-100
  performanceScore: number;      // 0-100
  wpHealthScore: number;         // 0-100
  priorityClassification: 'critical' | 'high' | 'medium' | 'low';
  breakdown: Record<string, number>;  // Detailed sub-scores
}
```

**Weights:** Security 40%, Performance 30%, WordPress Health 30%

**Security Score (40% of total):**
- SSL valid & not expiring soon: +30 points
- SSL expiring within 30 days: +15 points
- SSL expired or invalid: 0 points
- No critical vulnerabilities: +30 points
- Each critical vuln: -15 points (min 0)
- Each high vuln: -10 points (min 0)
- No config backups exposed: +20 points
- No DB exports exposed: +20 points
- Normalize to 0-100

**Performance Score (30% of total):**
- Direct mapping from PSI scores (already 0-100)
- Weighted: performance 40%, accessibility 20%, SEO 20%, best practices 20%
- If PSI unavailable: score = 50 (neutral)

**WordPress Health Score (30% of total):**
- WP version latest: +30 points
- WP version outdated: +15 points
- WP version insecure: 0 points
- Plugin count penalty: >20 plugins = -10, >30 = -20
- Each outdated plugin: -3 points
- Theme up to date: +20 points
- No exposed users: +20 points
- Normalize to 0-100

**Priority Classification:**
- Score <40 → `critical` (auto-qualify for outreach)
- Score 40-55 → `high`
- Score 55-75 → `medium` (manual review)
- Score >75 → `low`

Handle missing data gracefully: if a service failed, use neutral score (50) for that dimension and note it in breakdown.

**Verify:**
```bash
cd server && npx tsc --noEmit
```

**Done when:**
- `calculateScore(input)` returns composite score with breakdown
- Weights match spec: 40% security, 30% performance, 30% WP health
- Priority classification maps correctly to score ranges
- Missing data handled with neutral scores

---

### Task 7: Wire Services into Analysis Worker

**Files:** `server/src/workers/analysis-worker.ts`, `server/src/services/analysis/index.ts`

**Action:**

Create `server/src/services/analysis/index.ts` as the orchestrator:

```typescript
export async function analyzeSite(siteId: number, jobId: string): Promise<AnalysisResult> {
  // 1. Get site from DB
  // 2. Run PageSpeed Insights
  // 3. Run SSL analysis
  // 4. Run WPScan (if WordPress)
  // 5. Match vulnerabilities (if WPScan found plugins/themes)
  // 6. Calculate composite score
  // 7. Save to site_analyses table
  // 8. Update site analysis_status and tags
  // 9. Return result
}
```

Update the analysis worker (from Plan 1) to call `analyzeSite()` instead of placeholder:
- Replace placeholder service calls with real `analyzeSite()` calls
- Each site in the parallel batch calls `analyzeSite()`
- On success: update `analysis_status = 'analyzed'`, add `'analyzed'` tag
- On error: update `analysis_status = 'error'`, log error
- Non-WordPress sites: skip WPScan, still run PSI + SSL

**Verify:**
```bash
cd server && npx tsc --noEmit
```

**Done when:**
- `analyzeSite()` orchestrates all three services + scoring
- Worker calls real services instead of placeholders
- Results saved to `site_analyses` table
- Non-WordPress sites handled (PSI + SSL only)
- Tags updated on completion

---

## Verification

After all tasks complete:

```bash
# TypeScript compiles
cd server && npx tsc --noEmit

# Services are importable
cd server && npx tsx -e "
  const psi = require('./src/services/analysis/pagespeed');
  const ssl = require('./src/services/analysis/ssl-analyzer');
  const wps = require('./src/services/analysis/wpscan');
  const scoring = require('./src/services/analysis/scoring');
  const matcher = require('./src/services/analysis/vulnerability-matcher');
  console.log('All services loaded OK');
"

# Scoring engine produces valid output
cd server && npx tsx -e "
  const { calculateScore } = require('./src/services/analysis/scoring');
  const result = calculateScore({
    pagespeed: { performance: 45, accessibility: 60, seo: 70, bestPractices: 55, rawData: {} },
    ssl: { valid: false, issuer: null, subject: null, expiryDate: null, daysUntilExpiry: null, protocolVersion: null, cipher: null, cipherStrength: null, chainValid: false, selfSigned: false, errors: ['expired'], rawData: {} },
    wpscan: null,
    vulnerabilities: null,
  });
  console.log('Score:', result.healthScore, 'Priority:', result.priorityClassification);
"
```

## Success Criteria

- [ ] PageSpeed Insights service calls Google API and returns 4 scores
- [ ] SSL analyzer detects expired certs, weak protocols, chain issues using Node.js tls
- [ ] WPScan service executes via Docker and parses JSON output
- [ ] Vulnerability matcher queries local DB and falls back to APIs
- [ ] Vulnerability DB updater downloads and imports OWVD data
- [ ] Scoring engine produces 0-100 composite with correct weights (40/30/30)
- [ ] Priority classification maps to score ranges correctly
- [ ] All services wired into analysis worker
- [ ] Non-WordPress sites get PSI + SSL analysis (WPScan skipped)
- [ ] All code compiles with `tsc --noEmit`

## Output

**Files created:**
- `server/src/services/analysis/pagespeed.ts` — PageSpeed Insights API client
- `server/src/services/analysis/ssl-analyzer.ts` — SSL/TLS analysis via Node.js tls
- `server/src/services/analysis/wpscan.ts` — WPScan Docker execution and parsing
- `server/src/services/analysis/vulnerability-matcher.ts` — Local DB + API fallback matching
- `server/src/services/analysis/vuln-db-updater.ts` — OWVD download and import
- `server/src/services/analysis/scoring.ts` — Composite scoring engine
- `server/src/services/analysis/index.ts` — Analysis orchestrator

**Files modified:**
- `server/src/workers/analysis-worker.ts` — Wire real services instead of placeholders
- `server/src/routes/settings.ts` — Add vuln DB update/status endpoints
